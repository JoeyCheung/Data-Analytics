{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Support Vector Machine and Decision Trees\n",
    "\n",
    "# Due on 11/25 23:59 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use the same affair dataset from HW3, but will skip the EDA phrase we have done enough of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything removing outliers, create dummies variabes had been done for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>had_affair</th>\n",
       "      <th>occ2</th>\n",
       "      <th>occ3</th>\n",
       "      <th>occ4</th>\n",
       "      <th>occ5</th>\n",
       "      <th>occ6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  had_affair  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0           1   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0           1   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0           1   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0           1   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0           1   \n",
       "\n",
       "   occ2  occ3  occ4  occ5  occ6  \n",
       "0     1     0     0     0     0  \n",
       "1     0     1     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     1     0  \n",
       "4     0     1     0     0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember the affair data set from HW3, we will use that dataset again\n",
    "# but we will directly load it from the API\n",
    "orig_df = pd.read_csv(\"affairs2.csv\")\n",
    "# Set up our target class label\n",
    "orig_df['had_affair'] = orig_df['affairs'].apply(lambda x: 1 if x != 0 else 0)\n",
    "orig_df = orig_df.drop('affairs',axis=1)\n",
    "# remove NA\n",
    "orig_df.dropna(inplace=True)\n",
    "# create dummies variable for occupation\n",
    "occ = pd.get_dummies(orig_df['occupation'],drop_first=True)\n",
    "# we include rate_marriage feature as well. In HW3, we did not include that variable\n",
    "features = ['rate_marriage','age','yrs_married','children','religious','educ', 'had_affair']\n",
    "df = orig_df\n",
    "df = pd.concat([orig_df[features], occ], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate_marriage    0\n",
       "age              0\n",
       "yrs_married      0\n",
       "children         0\n",
       "religious        0\n",
       "educ             0\n",
       "had_affair       0\n",
       "occ2             0\n",
       "occ3             0\n",
       "occ4             0\n",
       "occ5             0\n",
       "occ6             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there is no missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Build a classification model using SVC using linear kernel with usual steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the model from sklearn import svm, create the SVC object \n",
    "#model = svm.SVC()\n",
    "#Call Train test split\n",
    "#print out model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[803  56]\n",
      " [295 120]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.93      0.82       859\n",
      "          1       0.68      0.29      0.41       415\n",
      "\n",
      "avg / total       0.72      0.72      0.69      1274\n",
      "\n",
      "0.724489795918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Now try different value of C-parameter and rerun your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear', C=2.0)\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[796  51]\n",
      " [301 126]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.94      0.82       847\n",
      "          1       0.71      0.30      0.42       427\n",
      "\n",
      "avg / total       0.72      0.72      0.68      1274\n",
      "\n",
      "0.723704866562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Try using rbf as your kernel and use Gamma of 2**-5, 0.1, 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='rbf', gamma=2**-5)\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[800  68]\n",
      " [292 114]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.92      0.82       868\n",
      "          1       0.63      0.28      0.39       406\n",
      "\n",
      "avg / total       0.70      0.72      0.68      1274\n",
      "\n",
      "0.717425431711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='rbf', gamma=0.1)\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[801  78]\n",
      " [257 138]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.91      0.83       879\n",
      "          1       0.64      0.35      0.45       395\n",
      "\n",
      "avg / total       0.72      0.74      0.71      1274\n",
      "\n",
      "0.73704866562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='rbf', gamma=1)\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[758  96]\n",
      " [299 121]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.89      0.79       854\n",
      "          1       0.56      0.29      0.38       420\n",
      "\n",
      "avg / total       0.66      0.69      0.66      1274\n",
      "\n",
      "0.689952904239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='rbf', gamma=2)\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[765  93]\n",
      " [350  66]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.89      0.78       858\n",
      "          1       0.42      0.16      0.23       416\n",
      "\n",
      "avg / total       0.60      0.65      0.60      1274\n",
      "\n",
      "0.652276295133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. So out of all the models you try in Question 3 and 4, what is the best choice for the kernel, C and gamma parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Kernel='rbf', C=1.0, gamma=0.1***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will try to fit the same dataset with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. Build a Decision Tree Classifier using default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[692 178]\n",
      " [228 176]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.80      0.77       870\n",
      "          1       0.50      0.44      0.46       404\n",
      "\n",
      "avg / total       0.67      0.68      0.68      1274\n",
      "\n",
      "0.681318681319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Now try using max_depth = 2, 3, 4 and crierion = 'gini' and 'entropy' to build 3 X 2 = 6 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[805  69]\n",
      " [281 119]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82       874\n",
      "          1       0.63      0.30      0.40       400\n",
      "\n",
      "avg / total       0.71      0.73      0.69      1274\n",
      "\n",
      "0.725274725275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=2, criterion='gini')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[815  76]\n",
      " [249 134]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83       891\n",
      "          1       0.64      0.35      0.45       383\n",
      "\n",
      "avg / total       0.73      0.74      0.72      1274\n",
      "\n",
      "0.744897959184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[814  57]\n",
      " [270 133]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.93      0.83       871\n",
      "          1       0.70      0.33      0.45       403\n",
      "\n",
      "avg / total       0.73      0.74      0.71      1274\n",
      "\n",
      "0.743328100471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[814  86]\n",
      " [252 122]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.90      0.83       900\n",
      "          1       0.59      0.33      0.42       374\n",
      "\n",
      "avg / total       0.71      0.73      0.71      1274\n",
      "\n",
      "0.734693877551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[779  74]\n",
      " [305 116]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.91      0.80       853\n",
      "          1       0.61      0.28      0.38       421\n",
      "\n",
      "avg / total       0.68      0.70      0.66      1274\n",
      "\n",
      "0.70251177394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[781  88]\n",
      " [273 132]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.90      0.81       869\n",
      "          1       0.60      0.33      0.42       405\n",
      "\n",
      "avg / total       0.70      0.72      0.69      1274\n",
      "\n",
      "0.716640502355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=4, criterion='entropy')\n",
    "X = df.drop('had_affair', axis=1)\n",
    "y = df['had_affair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7. What is your obsevation from Question 6? Does the choice of the criterion important in this case? What about the max_depth? What is the best choice of max_depth and criterion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***No, the criterion is not important. The max_depth is important. The best choice for max_depth is 3 and criterion is gini***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualization\n",
    "\n",
    "Scikit learn actually has some built-in visualization capabilities for decision trees, you won't use this often and it requires you to install the pydot library, but here is an example of what it looks like and the code to execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'yrs_married',\n",
       " 'children',\n",
       " 'religious',\n",
       " 'educ',\n",
       " 'had_affair',\n",
       " 'occ2',\n",
       " 'occ3',\n",
       " 'occ4',\n",
       " 'occ5',\n",
       " 'occ6']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import io\n",
    "import pydot \n",
    "\n",
    "features = list(df.columns[1:])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    706\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1332\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2db49f1ae0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(f, prog, encoding)\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0;34m\"\"\"Refer to docstring of method `create`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 return self.create(\n\u001b[0;32m-> 1723\u001b[0;31m                     format=f, prog=prog, encoding=encoding)\n\u001b[0m\u001b[1;32m   1724\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'create_{fmt}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[1;32m   1921\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(model, out_file=dot_data, feature_names=features)\n",
    "(graph, ) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8, now pick three models, with max_depth = 2, 3 and 4. You can pick the which ever criterions you want and visual the three trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint \n",
    "# model1 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model1.fit(X_train, y_train)\n",
    "# model2 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model2.fit(X_train, y_train)\n",
    "# model3 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model3.fit(X_train, y_train)\n",
    "# Then display all 3 trees\n",
    "# \n",
    "\n",
    "#dot_data = StringIO()  \n",
    "#export_graphviz(model1, out_file=dot_data, feature_names=features)\n",
    "#graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "#Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9. Now build a Random Forest Classifier with, say, 100 trees. Check the model performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
